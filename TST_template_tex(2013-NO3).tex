\documentclass[10.5pt,compsoc]{TsT}
\usepackage{graphicx}
\usepackage{footmisc}
\usepackage{subfigure}
\usepackage{url}
\usepackage{multirow}
\usepackage[noadjust]{cite}
\usepackage{amsmath,amsthm}
\usepackage{amssymb,amsfonts}
\usepackage{booktabs}
\usepackage{color}
\usepackage{ccaption}
\usepackage{booktabs}
\usepackage{float}
\usepackage{fancyhdr}
\usepackage{caption}
\usepackage{xcolor,stfloats}
\usepackage{comment}
\setcounter{page}{1}
\graphicspath{{figures/}}
\usepackage{cuted}  %flushend,
\usepackage{captionhack}
\usepackage{epstopdf}
%\usepackage[lite,subscriptcorrection,slantedGreek,nofontinfo]{mtpro2}

%===============================%
\headevenname{\zihao{-5}{\textbf{\emph{Tsinghua Science and Technology, June}}} 2013, 18(3): 000-000}%
\headoddname{{\sf Wang Zhenyang et al.:}\quad {\textbf{\emph{Attention to Difficult Instances: A Cascade Coarse to Fine Network Architecture for Semantic Segmentation}}}}%
%footnote use of *
\renewcommand{\thefootnote}{\fnsymbol{footnote}}
\setcounter{footnote}{0}
\renewcommand\footnotelayout{\normalsize}

\newtheoremstyle{mystyle}{0pt}{0pt}{\normalfont}{1em}{\bf}{}{1em}{}
\theoremstyle{mystyle}
\renewcommand\figurename{Fig.~}
\renewcommand{\thesubfigure}{(\alph{subfigure})}
\newcommand{\upcite}[1]{\textsuperscript{\cite{#1}}}
\renewcommand{\labelenumi}{(\arabic{enumi})}
\newcommand{\tabincell}[2]{\begin{tabular}{@{}#1@{}}#2\end{tabular}}
\newcommand{\abc}{\color{white}\vrule width 2pt}


\newtheorem{assumption}{\textbf{Assumption}}
\newtheorem{definition}{\textbf{Definition}}
\newtheorem{lemma}{\textbf{Lemma}}
\newtheorem{theorem}{\textbf{Theorem}}
\newtheorem{proposition}{\textbf{Proposition}}
\newtheorem{corollary}{\textbf{Corollary}}






%\newcommand{\TODO}[1]{\textbf{TODO: #1}}

\addtolength{\abovecaptionskip}{-2mm}
\addtolength{\belowcaptionskip}{-2mm}

%%% aanpassing van cite aan journal style
\makeatletter
%\def\@cite#1#2{\textsuperscript{[{#1\if@tempswa, #2\fi}]}}
\renewcommand{\@biblabel}[1]{[#1]\hfill}
\makeatother

\begin{document}

\thispagestyle{empty}

\begin{strip}\zihao{3}
\noindent
\\ \textbf{Template for Preparation of Manuscripts for \\ \emph{Tsinghua Science and Technology}}
\vskip 6mm
\zihao{5}

\noindent
This template is to be used for preparing manuscripts for submission to \emph{Tsinghua Science and Technology}. Use of this template will save time in the review and production processes and will expedite publication. However, use of the template is not a requirement of submission. Do not modify the template in any way (delete spaces, modify font size/line height, etc.).
\vspace{180mm}
\end{strip}
\clearpage

\hyphenpenalty=50000

\makeatletter
\newcommand\mysmall{\@setfontsize\mysmall{7}{9.5}}

%%%%%%%%%%%%%%%%%%%%%%%
\newenvironment{tablehere}
  {\def\@captype{table}}
  {}
\newenvironment{figurehere}
  {\def\@captype{figure}}
  {}
%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\thispagestyle{plain}%
\thispagestyle{empty}%

\let\temp\footnote
\renewcommand \footnote[1]{\temp{\zihao{-5}#1}}
{}
\vspace*{-40pt}

%{\hbox
\noindent{\zihao{5-}\textbf{\scalebox{0.89}[1.0]{\makebox[5.6cm][s]{%
TSINGHUA SCIENCE AND TECHNOLOGY}}}}

\vskip .2mm
{\zihao{5-}
\textbf{
\hspace{-5mm}
\scalebox{1}[1.0]{\makebox[5.6cm][s]{%
I\hspace{0.70pt}S\hspace{0.70pt}S\hspace{0.70pt}N\hspace{0.70pt}{\color{white}%
l\hspace{0.70pt}l\hspace{0.70pt}}1\hspace{0.70pt}0\hspace{0.70pt}0\hspace{0.70pt%
}7\hspace{0.70pt}-\hspace{0.70pt}0\hspace{0.70pt}2\hspace{0.70pt}1\hspace{0.70pt%
}4\hspace{0.70pt}{\color{white}l\hspace{0.70pt}l\hspace{0.70pt}}0\hspace{0.70pt}%
?\hspace{0.70pt}/\hspace{0.70pt}?\hspace{0.70pt}?\hspace{0.70pt}{\color{white}%
l\hspace{0.70pt}l\hspace{0.70pt}}p\hspace{0.70pt}p\hspace{0.70pt}?\hspace{0.70pt}?\hspace{0.70pt}?%
-\hspace{ 0.70pt}?\hspace{0.70pt}?\hspace{0.70pt}?}}}

\vskip .2mm\noindent
{\zihao{5-}\textbf{\scalebox{1}[1.0]{\makebox[5.6cm][s]{%
V\hspace{0.8pt}o\hspace{0.8pt}l\hspace{0.8pt}u\hspace{0.8pt}m\hspace{0.8pt}%
e\hspace{0.6em}1\hspace{0.8pt}8,\hspace{0.6em}N\hspace{0.8pt}u\hspace{0.8pt}%
m\hspace{0.8pt}b\hspace{0.8pt}e\hspace{0.8pt}r\hspace{0.6em}3,\hspace{0.6em}%
J\hspace{0.8pt}u\hspace{0.8pt}n\hspace{0.8pt}e%
\hspace{0.6em}2\hspace{0.8pt}0\hspace{0.8pt}1\hspace{0.8pt}3}}}}


\begin{strip}
{\center \vskip 3mm
{\zihao{3}\textbf{
Attention to Difficult Pixels: A Cascade Coarse to Fine Network Architecture for Semantic Segmentation
}}
\vskip 9mm}

{\center {\sf \zihao{5}
Wang Zhenyang, Deng Zhidong$^*$, and Wang Shiyao
}
\vskip 5mm}
%{\center \zihao{-5}{\textbf{
%1.~School of Computer Science, China University of Geosciences, Wuhan 430074, China;  \\
%2.~Shandong Provincial Key Laboratory of Computer Network, Jinan 250014, China; \\
%3.~School of Electronic Engineering Naval University of Engineering, Wuhan 430033, China\\
%}}}
%
%\vskip 5mm

\centering{
\begin{tabular}{p{160mm}}

{\zihao{-5}
\linespread{1.6667} %
\noindent
\bf{Abstract:} {\sf
Scene labeling, based on semantic segmentation, is a fundamental topic in computer vision. The goal is to assign each pixel in the image a category label. Convolutional neural networks, especially the fully convolutional neural networks, have attracted increasing attention on semantic segmentation due to the powerful capabilities of extracting hierarchical features. Since it is required to learn to make dense predictions for each pixel, a simple network is hardly to obtain considerable performances on different scenes. In this paper, we propose a novel semantic segmentation network called HMNet, which aims to pay more attention to the hard examples. The network has three branches, where the first branch produces coarse output predictions, and the second branch selects the hard examples which will be fed to the last branch. All above branches focus on their own objectives and collaboratively learn to predict from coarse to fine inference. Since the semantic segmentation dataset contains a large number of relatively easy samples and some hard ones, HMNet is encouraged to select these hard examples to make further predictions which is help to improve the final performance. In order to evaluate predicting performance of the proposed HMNet, we conduct experiments on two public datasets including Sift Flow and Stanford Background Dataset. We show that the three branches can be trained in an end-to-end manner and the experimental results show that compared to all existing models, our HMNet consistently yields the best performance, with accuracy of 91.6\% and 89.7\%, respectively.
}
\vskip 4mm
\noindent
{\bf Key words:} {\sf 
semantic segmentation; online hard example mining; convolutional neural network
}}

\end{tabular}
}
\vskip 6mm

\vskip -3mm
\zihao{6}\end{strip}


\thispagestyle{plain}%
\thispagestyle{empty}%
\makeatother
\pagestyle{tstheadings}

\begin{figure}[b]
\vskip -6mm
\begin{tabular}{p{44mm}}
\toprule\\
\end{tabular}
\vskip -4.5mm
\noindent
\setlength{\tabcolsep}{1pt}
\begin{tabular}{p{1.5mm}p{79.5mm}}
$\bullet$& Wang Zhenyang, Deng Zhidong, Wang Shiyao are with the Department of Computer Science, Tsinghua University, Beijing 100084, China. E-mail: crazycry2010@gmail.com, michael@tsinghua.edu.cn, sy-wang14@mails.tsinghua.edu.cn \\
$\sf{*}$&
To whom correspondence should be addressed. \\
          &          Manuscript received: 2017-09-20; revised: year-month-day; accepted: year-month-day

\end{tabular}
\end{figure}\zihao{5}



%\vspace{3.5mm}
\section{Introduction}
\label{s:introduction}
\noindent

Semantic segmentation, also known as scene labeling, is one of the fundamental research topics in computer vision. 
The goal of semantic segmentation is to identify and assign each pixel in the image with a category. 
This requires a complete understanding of the semantic information of the entire image. 
That means, for the testing image, it needs to predict the label of each object, and it is also very important to determine the boundary of each object in pixel level. 
Semantic segmentation has a strong application requirement in the field of environment perception and autonomous self driving car.

In recent years, deep learning has made breakthroughs in image classification, speech recognition, visual object recognition, object detection, and so on.
For the task of image semantic segmentation, there are also many methods based on deep learning methods.
Early research attempts to apply the convolution neural network designed for image recognition directly to semantic segmentation.
Although good segmentation results are obtained, the prediction results are rough and the edges of objects 
can not be separated correctly.
This is mainly cased by the losing of location information.
The fully convolutional neural network is proposed by~\ref{} to overcome this disadvantage, and become the most popular segmentation framework for semantic segmentation task.

In order to solve the problem of edge blur, conditional random field, Markov random field, Gaussian conditional random field, and other variations are proposed.
But with the development of network architecture, especially with the presenting of ResNet~\ref{} and batch normalization~\ref{}, an end-to-end training procedure can achieve a same even better segmentation results.


Another challenge is to simultaneously predict large and dense semantic labels, especially when the distribution of different classes is unbalanced.
An extreme unbalanced example is the background and foreground pixels.
In addition, the unbalance of easy and difficulty pixels can also affect the convergence of the network.
Aiming at the problem of unbalanced distribution of different difficulty pixels, we propose a novel semantic segmentation network framework based on the idea of hard negative example mining.

In fact, hard sample mining is not a new concept. As early as 1994, Sung and Poggio~\ref{} proposed bootstrapping method in their face detection algorithm.
The main purpose is to  enhance the algorithm's capacity by changing the distribution of difficult samples.
Inspired by the similar ideas, a cascade coarse to fine network architecture(CCFNet) is proposed.
CCFNet is composed by three branches which share a same feature extraction network.
The first branch is a coarse segmentation network which can predict correctly for most pixel.
The second branch is an attention network used to predict a degree of difficulty per pixel.
For the difficult pixels, the third segmentation branch is proposed to refine the final results.

For semantic segmentation tasks, each pixel should be assigned a prediction label.
So each training image contains a large number of optimization targets, which makes a single segmentation network be difficult to meet all the optimization goals.
CCFNet uses a multi-branch network structure, integrating the prediction from two different branches with an attention model to optimize the final segmentation results.

In conclusion, we propose a cascade coarse to fine network architecture for semantic segmentation.
Compared with the traditional semantic segmentation networks, CCFNet has the following characteristics: 
1. Propose a cascade segmentation network architecture to refine the final segmentation results.
2. Incorporate the idea of hard mining into an attention module.
3. Validate CCFNet on both Sift Flow Dataset and Stanford Background Dataset.


\section{Related Works}
\label{s:Related}
\noindent


\section{Method}
\label{s:Method}
\noindent


Inspired by online hard example mining(OHEM) algorithm, we propose a cascade coarse to fine network architecture CCFNet. 
Section~\ref{s:arch} illustrates how to turn a ImageNet pre-trained model to a cascade coarse to fine semantic segmentation network CCFNet.
Taking the characteristics of semantic segmentation task into consideration, section~\ref{s:hard} introduces a hard instance mining method to learn the attention about the difficulty of each instance.
Section~\ref{s:hard} detailes the training and testing process of CCFNet. 
%The idea behind is  simple yet effective. 
%The segmentation datasets contain a large number of easy examples and a small number of hard examples.
%Paying more attention on these hard examples can make the training 
%Pay much more attention on these hard examples 

\subsection{Cascade Coarse to Fine Network Architecture}
\label{s:arch}
\noindent

We choose ResNet-50 pre-trained on ImageNet as our baseline model.
ResNet originally is designed for image classification which win ILSRVC 2015 competation and surpass the human performance on ImageNet dataset.
ResNet-50 is one of the version provided in experiments, which is faster than VGG-16 and more accurate than VGG-19.
Compared with ResNet-101, ResNet-50 is cheaper in computation resources and memory consumption, but can achieve a comparable accuracy.
Figure~\ref{f:arch}a  visualizes the network architecture of ResNet-50, which is composed by five stages with different configurations of layers and a classification stage.
We treat the ResNet-50 as a common feature extraction part of CCFNet by discarding the classification stage.


The architecture of CCFNet is shown as Fig.~\ref{f:arch}b, which is composed by three cascade network branches: a coarse segmentation branch as a baseline result, an attention branch to predict the difficulty of labeling each pixel instance, and a refine segmentation branch to refine the final segmentation results. 
These three branches share a common feature extraction network.

\textbf{The feature extraction network} is a fundamental convolutional neural network.
A modified version of ResNet-50 is adopted by this paper.
For semantic segmentation task,  the context is important to predict the correct label of each pixel instance.
But it is difficult to determine the boundary of each pixel's context, since different objects may have different sizes.
And the problem gets more complicated when considering the various perspective of each images.
A simple yet effective method to solve this problem is to integrate multi-scale features for label predicting.
The residual error model itself has the property of extracting and integrating multi-scale features, which can be seen from Fig.~\ref{}.
From the unravelled view by Veit et al.~\ref{}, a two-unit ResNet is equivalent to an ensemble of four sub-networks with different receptive fields , as illustrated in Fig. ~\ref{}.
So the whole ResNet-50 can be expanded as a linearly growing ensemble of sub-networks, which can extract and integrate multi-scale features.

Besides, there are two improvements adopted by ResNet-50 to make it more suitable for segmentation task.
First, we only keep the first three pooling layers to preserve the resolution.
So the final resolution of prediction is 1/8 of the original input image. 
Secondly, we replace the convolutional layer in the last two stages with the dilated convolutions.
It can help to enlarge the reception field of predicted feature maps.
The modified ResNet-50 is used as feature extraction network in CCFNet.

\textbf{The coarse segmentation branch} is a baseline model for image semantic segmentation.
This branch is shown as the red part in Fig.~\ref{f:arch} b, we adopt a fully convolutional network(FCN) with two convolutional layers to predict the semantic classes for their regions.
Since the resolution is 1/8 of the original input image, the feature maps are up-sampled by bilinear interpolation.
Finally, a pixel-wise softmax loss is adopted to predict the probabilities of each pixel.


\textbf{The attention branch} is proposed to learn a soft-attention, which is a one-channel feature map with the same resolution as the input image. 
It is mainly used to indicate the segment difficulty of each pixel.
The idea behind is simple yet effective. 
The segmentation datasets contain a large number of easy pixel instances and a small number of difficulty pixel instances.
Paying more attention on these difficulty pixel instances can make the training process converges faster and efficiently.
The attention branch shares the same feature extraction network as the coarse segmentation branch, and has a similar network structure.
The major different is that the attention branch is a two-category semantic segmentation network which is only used to predict the segment difficulty.
Just the same as the coarse segmentation branch, softmax layer is adopted again to generate a soft-attention weighting coefficient.


\textbf{The refine segmentation branch} refines the segmentation results as the final network output.
This branch is more complicated compared with the first two branches.
The coarse segmentation branch is hard to segment all the pixels correctly.
So the pixel instances can be divided into two groups by the coarse segmentation branch.
The pixels which can be segment correctly by the coarse segmentation branch is denote as easy pixel instances, while the others are difficult ones.
A fine segmentation network is introduced to reclassification the difficult pixel instances.
Inspired by the PSPNet~\ref{}, pyramid pooling is adopted by the fine segmentation network to extract multi-scale features.
And the refine segmentation branch is a weighted summation of the coarse segmentation branch and the fine segmentation network, with the weighting coefficient predicted from the attention branch.
So an end-to-end learning branch is proposed to learn the final segmentation result directly.

The three branches are cascaded one by one, and constitute an end-to-end learning network with multiple loss functions.

%The simplest method to improve the segmentation result is by applying a reclassification for the difficult pixel instances.
%But an unbalanced sample distribution go against the convergence of the reclassification network.
%So we propose an end-to-end learning branch, the refine segmentation branch, to learn the final segmentation result directly.


\subsection{Attention to Difficulty Pixels}
\label{s:attention}
\noindent


Hard example mining is one of the commonly used training techniques for machine learning.
The traditional implement is a continuous iterative process which could be divided into two steps.
Firstly, the training model is fixed to screen out the difficult examples, and the training set is updated by adding a certain rate of difficult examples.
Secondly, in the fixed training set, the training model is re-trained.

In this paper, the two-step process of hard example mining is optimised to an end-to-end learning network framework.
For semantic segmentation task, each pixel should be assigned a category label.
So a single image contain enough training samples for hard example mining.
The attention branch is used to predict each pixel is easy or difficult for the coarse segmentation branch.
It makes the end-to-end learning possible by heuristically filtering out the hard examples online.
The final segmentation results relay more on the coarse segmentation branch if the pixel is predicted as an easy one.
Otherwise, the fine segmentation network takes up a larger proportion.
Inspired by online hard example mining, the attention branch with a heuristic strategy is introduced to CCFNet to predict the difficult of each pixel.
And the final segmentation results are promoted by hard sample selection.

During the training process, the attention branch is supervised by a label map with 0/1 values, indicating  easy or difficult for the pixel in corresponding position.
The attention branch is cascaded behind the coarse segmentation branch, so the 0/1 label map can be generated by a comparison between the prediction of the coarse segmentation branch and the segmentation ground truth.
0 indicates the pixel is misclassified by the coarse segmentation branch, while 1 represents a correctly prediction.
The 0/1 label map is used as the ground truth of the attention branch, supervising the attention branch to learn the difficulty of each pixel.


\section{Experimental results}
\label{s:results}
\noindent

\subsection{Network Configuration}
\noindent


\subsection{Data Sets}
\noindent

\subsection{Comparison Results}
\noindent

\subsection{Results Visualization}
\noindent


\section{Conclusions}
\noindent
For example: The parallelization of cutoff pair interactions is mature on CPUs, and typically employs a voxel-based method.


\vskip 6mm
\noindent
References to the literature are cited by \emph{number in square brackets} at appropriate locations (\emph{before} a period, comma, etc.) in the text.

\vskip 6mm
\noindent
Examples:

\setlength{\hangindent}{18pt}
\noindent
  $\bullet$  	Negotiation research spans many disciplines [3].

\setlength{\hangindent}{18pt}
\noindent
  $\bullet$  	This result was later contradicted by Becker and Seligman [5, 6], who .......

\setlength{\hangindent}{18pt}
\noindent
  $\bullet$  	This effect has been widely studied [1-3, 7].

\setlength{\hangindent}{18pt}
\noindent
  $\bullet$  	......achieved until rather recently [11, 21, 22], with......

\setlength{\hangindent}{18pt}
\noindent
  $\bullet$  	......stage of cap formation (see Fig. 5 in Ref. [14]).

\vskip 2mm
\zihao{5}
\noindent
\textbf{Acknowledgements}
\vskip 2mm

\zihao{5--}
\noindent
This work was supported in part by the National Science Foundation of China (NSFC) under Grant Nos. 91420106, 90820305, and 60775040, and by the National High-Tech R\&D Program of China under Grant No. 2012AA041402.

\vskip 2mm
\zihao{5}
\noindent
\textbf{\zihao{5}References}
\vskip 2mm

\zihao{5-}
\noindent
The font is Times New Roman $\backslash$zihao\{5\--\}. This part is placed at the end of the manuscript. References should be numbered sequentially as they appear throughout the text. Only one publication should be given for each number. The list of references should only include papers that have been published or accepted by a named publication or recognized preprint server. Authors should ensure the accuracy and completeness of all references before submission. Please ensure references are given in the correct style as shown below in order to avoid delays in typesetting your article
\renewcommand\refname{\zihao{5}\textbf{References}}


\begin{thebibliography}{99}
\zihao{5-} \addtolength{\itemsep}{-1em}
\vspace {1.5mm}

\bibitem[1]{1}
M. Abrahams and M. Kattenfeld, ¡°The role of turbidity as a constraint on predator-prey interactions in aquatic environments,¡± \emph{Behav. Ecol. Sociobiol.,} vol. 40, no. 3, pp.169-174, Mar. 1997. \textbf{(Journal style)}

\bibitem[2]{2}
R. C. Calfee and R. R. Valencia, \emph{APA Guide to Preparing Manuscripts for Journal Publication}. Washington, DC: American Psychological Association, 1991. \textbf{(Authored book style)}

\bibitem[3]{3}
J. M. O¡¯Neill and J. Egan, ¡°Men¡¯s and women¡¯s gender role journeys: metaphor for healing, transition, and transformation,¡± in \emph{Gender Issues Across the Life Cycle}, B. R. Wainrib, Ed. New York: Springer, 1992, pp. 107-123. \textbf{(Book chapter style)}

\bibitem[4]{4}
J. C. Phelan, B. G. Link, A. Stueve, and B. A. Pescosolido, ¡°Have public conceptions of mental health changed in the past half century? Does it matter?¡± presented at the 124th Annu. Meeting American Public Health Association, New York, USA, 1969. \textbf{(Paper presented at conferences style)}

\bibitem[5]{5}
A. Mahdavi and B. Spasojevic, ¡°Incorporating simulation into building systems control logic,¡± In \emph{Proc. 10th Int. Building Performance Simulation Association Conf.}, Beijing, China, 2007, pp. 1175-1181. \textbf{(Paper in proceedings style)}

\bibitem[6]{6}
X. Yang, ¡°Study of building material emissions and indoor air quality,¡± Ph.D. dissertation, Dept. Arch., MIT, MA, USA, 1999. \textbf{(Dissertation style)}

\bibitem[7]{7}
J. Dong, S. Martin, and P. Waldo, ¡°Method and system for dynamically presenting cluster analysis results,¡± US Patent US6380937B1, March 30, 2002. \textbf{(Patent style)}

\bibitem[8]{8}
Y. Jiang, ¡°Liquid desiccant air-conditioning system and its applications,¡± (in Chinese), \emph{Heating Ventilating \& Air Conditioning}, vol. 34, no. 11, pp. 88-97, 2004. \textbf{(Non-English publication style)}

\bibitem[9]{9}
M. K. Slifka and J. L. Whitton, ¡°Clinical implications of dysregulated cytokine production,¡± \emph{J. Mol. Med.}, doi:10.1007/s001090000086. \textbf{(Article by DOI style)}

\bibitem[10]{10}
J. Doe. The dictionary of substances and their effects,  http://www.rsc.org/ dose/title, 1999, Jan. 15. \textbf{(Online document style)}
  \end{thebibliography}

\begin{strip}
\end{strip}

\begin{biography}[yourphotofilename.eps]
\noindent
\textbf{First A. Author}\ \  Photo. Biographies should be limited to one paragraph consisting of the following: sequentially ordered list of degrees, including years achieved; sequentially ordered places of employ concluding with current employment; associa-tion with any official journals or conferences; major profes-sional and/or academic achievements, i.e., best paper awards, research grants, etc.; any publication information (number of papers and titles of books published); current research interests; association with any professional associations.
\end{biography}

\begin{biography}[yourphotofilename.eps]
\noindent
\textbf{Second B. Author} Photo. Biographies should be limited to one paragraph consisting of the following: sequentially ordered list of degrees, including years achieved; sequentially ordered places of employ concluding with current employment; associa-tion with any official journals or conferences; major profes-sional and/or academic achievements, i.e., best paper awards, research grants, etc.; any publication information (number of papers and titles of books published); current research interests; association with any professional associations.
\end{biography}
\vskip 22mm
\begin{biography}[yourphotofilename.eps]
\noindent
\textbf{Third C. Author}  Photo. Biographies should be limited to one paragraph consisting of the following: sequentially ordered list of degrees, including years achieved; sequentially ordered places of employ concluding with current employment; associa-tion with any official journals or conferences; major profes-sional and/or academic achievements, i.e., best paper awards, research grants, etc.; any publication information (number of papers and titles of books published); current research interests; association with any professional associations.
\end{biography}



  \end{document}


